{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.amazonaws.com/southfloridareporter/wp-content/uploads/2018/08/02194523/reddit-1-logo-png-transparent.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content:\n",
    "1. [Problem statement](#Problem-statement)\n",
    "2. [Library importing](#*Library-importing*)\n",
    "3. [Data scraping](#Data-scraping)\n",
    "4. [Data cleaning](#Data-cleaning)\n",
    "5. [Data Dictionary](#Data-Dictionary)\n",
    "5. [Text preprocessing](#Text-preprocessing)\n",
    "6. [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "7. [Text analysis](#Text-analysis)\n",
    "8. [Modeling](#Modeling)\n",
    "9. [Best model evaluation](#Best-model-evaluation)\n",
    "10. [Word inspection](#Word-inspection)\n",
    "11. [Misclassification analisys](#Misclassification-analisys)\n",
    "12. [Further research suggestions](#Further-research-suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Models are evaluated by **Classification accuracy, precision, recall and f1 score**.\n",
    "\n",
    "[Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) is the total percent of predictions a model gets right.\n",
    "\n",
    "$$\\text{Accuracy}={\\frac{True Positive + True Negative}{True Positive + True Negative + False Positive + False Negative}}$$\n",
    "_____\n",
    "[Precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) is the ratio of correctly predicted positive observations to the total predicted positive observations.\n",
    "\n",
    "$$\\text{Precision}={\\frac{True Positive}{True Positive + False Positive}}$$\n",
    "_____\n",
    "[Recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) is the ratio of correctly predicted positive observations to the all observations in positive class.\n",
    "\n",
    "$$\\text{Recall = Sensitivity}={\\frac{True Positive}{True Positive + False Negative}}$$\n",
    "_____\n",
    "[F1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) score is weighted average of the precision and recall. F1 score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "$$\\text{Recall = Sensitivity}={\\frac{2 * Precision * Recall}{Precision + Recall}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The goals of project:\n",
    "\n",
    "- Using Reddit's API, collect posts from two subreddits (Psychology and Astrilogy).\n",
    "- Use NLP to train a classifier on which subreddit a given post came from. This is a binary classification problem.\n",
    "\n",
    "#### The resulting model can be useful for layman people who cannot decide if the information comes from psychological science or astrological pseudoscience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Library importing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime as dt\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing import preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,roc_auc_score\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "%%capture\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()\n",
    "from IPython.display import display_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was scraped from [reddit](https://www.reddit.com/)\n",
    "\n",
    "The finction collects text (title+selftext) (str), number of comments (int), number of ups (int), date of post (timestamp/float), subreddit names (str)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_scraper(link_list,num_iter=10,act=True):\n",
    "    \"\"\"\n",
    "    Scrapes text and subreddit from links on reddit.com (json)\n",
    "    Saves info to csv to ./data/\n",
    "    \n",
    "    Takes:\n",
    "        act=True - (bool) - activates the function.\n",
    "        link_list - list of links to subreddits.\n",
    "        num_iter=10 (int) - number of iteration through links (100 posts per iter).\n",
    "    \n",
    "    Returns:\n",
    "        Reading from saved csv with:\n",
    "            text (title+selftext) (str),\n",
    "            number of comments (int),\n",
    "            number of ups (int),\n",
    "            date of post (timestamp/float),\n",
    "            subreddit names (str)\n",
    "    \"\"\"\n",
    "    # Creating empty list for posts\n",
    "    if act:\n",
    "        result = []\n",
    "        posts = []\n",
    "        # Loopong through links\n",
    "        for link in tqdm(link_list):\n",
    "            after = None\n",
    "            for a in tqdm(range(num_iter)):\n",
    "                params = {'after': after,'limit':200}\n",
    "                res = requests.get(link,params =params,headers={'User-agent': 'Unicorn Tail'})\n",
    "                if res.status_code != 200:\n",
    "                    print('Status error', res.status_code)\n",
    "                    break\n",
    "                # Scrapes data from links and add info to posts list\n",
    "                dict_json = res.json()\n",
    "                posts.extend(dict_json['data']['children'])\n",
    "                after = dict_json['data']['after']\n",
    "                # generate a random sleep duration to look more 'natural'\n",
    "                sleep_duration = random.randint(1,2)\n",
    "                time.sleep(sleep_duration)\n",
    "            print(f'Done for {link[25:-5]}')\n",
    "\n",
    "        # Adding title + selftext, num_comments, ups, date and subreddit to result\n",
    "        for row in range(len(posts)):\n",
    "            text = posts[row]['data']['title']+' '+posts[row]['data']['selftext']\n",
    "            result.append({'text':text,\n",
    "                        'num_comments':posts[row]['data']['num_comments'],\n",
    "                        'ups':posts[row]['data']['ups'],\n",
    "                        'date':posts[row]['data']['created_utc'],\n",
    "                        'subreddit':posts[row]['data']['subreddit'],})\n",
    "\n",
    "\n",
    "        # Adding data to csv file\n",
    "        pd.DataFrame(result).to_csv('./data/psy_astro.csv', index = False,header=True)\n",
    "        # Returning DataFrame with info for saved file\n",
    "        return pd.read_csv('./data/psy_astro.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping posts from r/psychology and r/astrology with 10 itteration (with limit = 100).\n",
    "\n",
    "To activate scrapping change act=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = reddit_scraper(['https://www.reddit.com/r/psychology.json',\n",
    "                       'https://www.reddit.com/r/astrology.json',\n",
    "                     ],num_iter=10,act=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readding data from csv (to avoid overwrite data from scraping)\n",
    "df = pd.read_csv('./data/psy_astro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that scraper got texts, number of comments, number of ups, data and subreddit names correctly. Let's look at the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1640, 7)"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the original shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some posts can be duplicated, we will drop all duplicates based on 'text' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all duplicated rows\n",
    "df.drop_duplicates(subset='text',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1635, 7)"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the resulting shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that 230 rows were dropped because they had the same text. Now the dataset contains 1642 rows and 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    905\n",
       "1    730\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.553517\n",
       "1    0.446483\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at distribution of classes of subreddits\n",
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of 'astrology' rows (907/0.55%) exceeds the number of 'psychology' rows (735/0.45%), the dataset is almost balanced, so we will not delete any other rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text            0\n",
       "num_comments    0\n",
       "ups             0\n",
       "date            0\n",
       "subreddit       0\n",
       "len_text        0\n",
       "hours           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null values. Let's check for data types of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                    object\n",
       "num_comments             int64\n",
       "ups                      int64\n",
       "date            datetime64[ns]\n",
       "subreddit                int64\n",
       "len_text                 int64\n",
       "hours                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data types are good except date because the timestamp is unclear for understanding. The convertation of timestamps to date will be executed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type Timestamp)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-697-df8ea54219eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convetring timestamp to date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3848\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-697-df8ea54219eb>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convetring timestamp to date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required (got type Timestamp)"
     ]
    }
   ],
   "source": [
    "# Convetring timestamp to date\n",
    "df['date'] = df['date'].apply(lambda x: dt.fromtimestamp(x))\n",
    "df['date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dates are understandable.\n",
    "\n",
    "The clean is saved to csv file clean_subreddits.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/clean_subreddits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "| Feature name | Type           | Description                                |\n",
    "| ------------ | -------------- | ------------------------------------------ |\n",
    "| text         | str            | Title + self text of post                  |\n",
    "| num_comments | int            | Number of comments under a post            |\n",
    "| ups          | int            | Number of ups of post                      |\n",
    "| date         | datetime64[ns] | Date of publication of post                |\n",
    "| subreddit    | str            | Name of subreddit (Psychology / Astrology) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step will be text preprocessing for the following exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing tegs\n",
    "df['text'] = df['text'].map(lambda x: BeautifulSoup(x).get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing non-letters\n",
    "df['text'] = df['text'].map(lambda x:re.sub(\"[^a-zA-Z]\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating Tokenizer and setting a pattern to only words\n",
    "# applying Tokenizer to texts\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df['text'] = df['text'].map(lambda x: tokenizer.tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the result\n",
    "df['text'][2][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each documents look like list of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the dates when posts were published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sorting table based on date\n",
    "df.sort_values(by='date',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posts in the dataset were published between 2020-05-13 21:05:19 and 2020-02-28 05:16:12. It means that the most recent data in 4 months were scraped.\n",
    "\n",
    "Only one post was published 2019-04-11 04:19:34 - the text from the post points out that the post is a moderator's post, the row can be removed then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=962,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare text metrics, a new column with a length of texts will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new feature of length of texts by words\n",
    "df['len_text'] = df['text'].apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the length of documents in details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('subreddit')['len_text'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astrology subreddit's posts have significantly more words than Psychology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('subreddit')['len_text'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and median of the number of words also very vary by subreddits. The average astrological document has 95 (mean) and 42.5 (median) words, although psychological documents have fewer words: 21 (mean) and 13 (median). The standard deviation for psychology is only 21 word and 177 for astrology. The minimum numbers of words in posts are 2 and 3, the maximum are significantly vary (almost 8 times): 2033 words for astrology and 274 for psychology.\n",
    "\n",
    "\n",
    "It is noticeable that the mean and median differ, the standard deviation in astrological documents are high (177 words) which means that there are some outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['len_text'] <= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14 documents have 3 or fewer words in them. Most of them still can be recognized by specific words for a topic. Some of the short texts have many comments and ups. These posts could contain videos or photos which are not out of our project scope but could be explored further in other projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['len_text'] > 200]['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 3 documents consist of more than 300 words in 'Psychology' and 91 in 'Astrology'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating distribution of number of words in documents by subreddits\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "psy = df[df['subreddit']=='psychology']['len_text']\n",
    "astr = df[df['subreddit']=='astrology']['len_text']\n",
    "\n",
    "sns.distplot(psy,label='psychology',color='#65a8a7',bins=30)\n",
    "sns.distplot(astr,label='astrology',color='#fcba03',bins=30)\n",
    "plt.legend(loc='upper right',fontsize=15)\n",
    "plt.title('Distribution of number of words in documents\\n',fontsize=18)\n",
    "plt.xticks(range(0,2150,150))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions differ by subreddits. But both distributions are very skewed towards the right. That means few posts have a significantly larger number of words than average. But psychological  posts' length distributed steeper than astrological."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a boxplot for text length by subreddits\n",
    "df.boxplot(column='len_text',by='subreddit',figsize=(8,6),vert=False)\n",
    "plt.title('Difference in subreddits\\' text length\\n\\n')\n",
    "plt.ylabel('Number of words');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that astrological posts have many outliers and some anomalies.\n",
    "\n",
    "We can conclude that people who write posts for an astrological subreddit prefer to use more words (and sometimes even more than 1000 words) than those who writing posts for a psychological subreddit.\n",
    "\n",
    "Number of comments will be explored next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting table based on number of comments\n",
    "df.sort_values(by='num_comments',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that there is one row (index 1866) that contains an anomaly number of comments - 1192. The row will be removed for better analysis of distribution but it will be kept separately for potential individual exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping a row with an anomaly and saving it separetely\n",
    "most_commented_post = df.loc[1866,:].copy(deep=True)\n",
    "df.drop(index=1866,inplace=True)\n",
    "# Astrology post with an outstanding number of comments\n",
    "most_commented_post['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics of number of comments\n",
    "df.groupby('subreddit')['num_comments'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astrological community writing more comments to posts than psychological one: mean for astrology is 20 (8 median) and 12 (1 median) for psychology. Difference between median and mean indicates the presence of outliers. Visualisation of a number of commentaries by subreddits presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a boxplot and distribution for number of comments by subreddits\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2,squeeze=False,figsize=(15,5))\n",
    "psy = df[df['subreddit']=='psychology']['num_comments']\n",
    "astr = df[df['subreddit']=='astrology']['num_comments']\n",
    "\n",
    "sns.boxplot(y='num_comments', x='subreddit', data=df, width=0.5,\n",
    "                 palette=\"BrBG\",ax=ax[0, 0])\n",
    "\n",
    "sns.distplot(psy,label='psychology',color='#65a8a7',bins=30)\n",
    "sns.distplot(astr,label='astrology',color='#fcba03',bins=30)\n",
    "plt.suptitle('Difference in subreddits\\' in number of comments',fontsize=16)\n",
    "plt.legend(loc='upper right',fontsize=13)\n",
    "plt.ylabel('Distribution')\n",
    "plt.xlabel(\"Number of comments\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From visualization above (based on high of the boxplot and less skewness of distribution towards the right) we can conclude that Astrological community members are involved more in feedbacks under the posts than psychological community. Some astrological posts have outstanding number of comments.\n",
    "\n",
    "A number of ups will be explored below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting table based on number of ups\n",
    "df.sort_values(by='ups',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a boxplot and distribution for number of ups by subreddits\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2,squeeze=False,figsize=(15,5))\n",
    "psy = df[df['subreddit']=='psychology']['ups']\n",
    "astr = df[df['subreddit']=='astrology']['ups']\n",
    "\n",
    "sns.boxplot(y='ups', x='subreddit', data=df, width=0.5,\n",
    "                 palette=\"BrBG\",ax=ax[0, 0])\n",
    "\n",
    "sns.distplot(psy,label='psychology',color='#65a8a7')\n",
    "sns.distplot(astr,label='astrology',color='#fcba03')\n",
    "plt.suptitle('Difference in subreddits\\' in ups\\n\\n',fontsize=16)\n",
    "plt.legend(loc='upper right',fontsize=13)\n",
    "plt.ylabel('Distribution')\n",
    "plt.ylabel('Number of ups');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics of number of ups\n",
    "df.groupby('subreddit')['ups'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above demonstrates that posts with the highest number of ups are all psychological. The boxplots and distributions illustrate the same trend: psychological community more than astrological one rate posts with ups. From this, we can conclude that feedbacks for posts in psychological subreddit carried out with ups although in astrological subreddit based on comments.\n",
    "\n",
    "Next step is the exploration of the time pattern of posts published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting hours from date when posts were published\n",
    "df['hours'] = df['date'].map(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of posts by the hour they post in by subreddits\n",
    "plt.figure(figsize=(10,6))\n",
    "psy = df[df['subreddit']=='psychology']['hours']\n",
    "astr = df[df['subreddit']=='astrology']['hours']\n",
    "\n",
    "sns.boxplot(y='ups', x='subreddit', data=df, width=0.5,\n",
    "                 palette=\"BrBG\",ax=ax[0, 0])\n",
    "\n",
    "sns.distplot(psy,label='psychology',color='#65a8a7')\n",
    "sns.distplot(astr,label='astrology',color='#fcba03')\n",
    "plt.legend(loc='upper right',fontsize=13)\n",
    "plt.xticks(range(24))\n",
    "plt.ylabel('Distribution')\n",
    "plt.ylabel('Number of ups');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a noticeable pattern of hours when posts were published. Majority of posts were published between 9 p.m and 3 a.m time, interestingly, that people prefer to publish their posts at night or very early morning. Much fewer people active in publication during lunch and after the lunchtime period (12-15 hours). Psychological posts were published later at night than astrological. Morning activity (from 8 to 10 a.m) can be seen for astrological subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== UNCOMMENT ===================\n",
    "# Pairplot for all columns in dataset hue by subreddits\n",
    "# sns.pairplot(df,hue='subreddit',palette=\"BrBG\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of comments plotted against the number of ups and number of ups by hours showed visual separation between two subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of intercorrelations\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of matrix of intercorrelations\n",
    "sns.heatmap(df.corr(),annot=True,cmap=\"BrBG\")\n",
    "plt.title('Correlation of features\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the matrix of intercorrelations above can be seen that only ups and number of comments have a moderate correlation (0.47 coefficient). Other columns do not correlate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for t ext preprocessing\n",
    "def text_preprocessing(df,columns_list,is_lem=True,is_stem=True):\n",
    "    '''\n",
    "    Lemmatize, Stemming list of words and concatenates in one string\n",
    "    \n",
    "    Takes:\n",
    "        df - DataFrame\n",
    "        columns_list - (list if str) - list with column' names with list of words\n",
    "        is_lem=True - (bool) - activate WordNetLemmatizer\n",
    "        is_stem=True - (bool) - activate PorterStemmer\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with concatenated list of words\n",
    "    '''\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    p_stemmer = PorterStemmer()\n",
    "    for column in columns_list:\n",
    "        if is_lem:\n",
    "            df[column] = df[column].apply(lambda row: [lemmatizer.lemmatize(text)\n",
    "                                     for text in row])\n",
    "        if is_stem:\n",
    "            df[column] = df[column].apply(lambda row: [p_stemmer.stem(text)\n",
    "                                     for text in row])\n",
    "        df[column] = df[column].apply(lambda row: ' '.join(word for word in row))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating list of words in strings row-wise, \n",
    "# disabling Lemmatizer and PorterStemmer for better readability of words, \n",
    "# number of words in posts is not high so Lemmatizer and PorterStemmer are not necessary\n",
    "df = text_preprocessing(df,['text'],is_lem=False,is_stem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the target variable from strings to ints. Psychology is a positive target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning 'psychology' as a positive class 1, astrology as 0\n",
    "df['subreddit'] = df['subreddit'].map({'psychology':1,'astrology':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning X to text and y to subreddits\n",
    "X = df['text']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing dataset into train and test subsets, saving the distribution ratio of the target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom stopwords from two packages and words from subreddits \n",
    "# which clearly points out affiliation with subreddits to make classification more challenging\n",
    "all_stop_words = set(list(stopwords.words('english')) + list(preprocessing.STOPWORDS) + \n",
    "                    ['psychology', 'astrology',\n",
    "                     'psychological','astrological','psychologist','astrologist','https','www',\n",
    "                    'reddit','com','s','th','r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 402 stopwords were defined\n",
    "len(all_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize most frequent words in texts for both subreddits.\n",
    "\n",
    "The code was taken from [here](https://www.geeksforgeeks.org/generating-word-cloud-python/) and modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating separated df for psychology and astrology\n",
    "words = pd.DataFrame({'text':X_train,\n",
    "                      'subreddit':y_train})\n",
    "words_psy = words[words['subreddit']==1]\n",
    "words_astr = words[words['subreddit']==0]\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,8))\n",
    "stopwords = list(set(STOPWORDS))\n",
    "\n",
    "# Converting separate documents into one string for each subreddit and creating wordclouds\n",
    "comment_words_psy = ''\n",
    "comment_words_psy += \" \".join(word for word in words_psy['text'])+\" \"\n",
    "wordcloud_psy = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = set(list(all_stop_words) + stopwords),\n",
    "                min_font_size = 5).generate(comment_words_psy) \n",
    "  \n",
    "comment_words_astr = ''\n",
    "comment_words_astr += \" \".join(word for word in words_astr['text'])+\" \"\n",
    "wordcloud_astr = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = set(list(all_stop_words) + stopwords),\n",
    "                min_font_size = 10).generate(comment_words_astr) \n",
    "\n",
    "# Plotting the WordCloud images\n",
    "ax[0].imshow(wordcloud_psy)\n",
    "ax[1].imshow(wordcloud_astr)\n",
    "ax[0].set_title('Most frequent words in Psychological posts\\n',fontsize=16)\n",
    "ax[1].set_title('Most frequent words in Astrologival posts\\n',fontsize=16)\n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 2) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clearly seen that only few words in both subreddits are repeating: people, new. Other words can be helpful for distinguishing subreddits. For psychology these words are study, research, anxiety, discussion, social etc. For Astrology are sign, chart, planet, house, mars, time ect.\n",
    "\n",
    "Let's use CountVectorizer and TfidfVectorizer for comparison of most important words for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing two vectorizers\n",
    "# maximum number of words is 5000, used custom stopwords\n",
    "cvec = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = all_stop_words,\n",
    "                             max_features = 5000)\n",
    "tvec = TfidfVectorizer(stop_words = all_stop_words,\n",
    "                             max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(820, 5721)\n",
      "(820, 5721)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing words for train dataset: fit the model and learn train vocabulary \n",
    "# and transforming strings info feature vectors\n",
    "\n",
    "# CountVectorizer\n",
    "train_features_cvec = cvec.fit_transform(X_train)\n",
    "print(train_features_cvec.shape)\n",
    "\n",
    "# TfidfVectorizer\n",
    "train_features_tvec = tvec.fit_transform(X_train)\n",
    "print(train_features_tvec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>abducted</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abnormally</th>\n",
       "      <th>abound</th>\n",
       "      <th>...</th>\n",
       "      <th>zircan</th>\n",
       "      <th>zk</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zodiacal</th>\n",
       "      <th>zodiacs</th>\n",
       "      <th>zodiacum</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwillinge</th>\n",
       "      <th>zxmoaplo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5721 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  ab  abducted  abhor  abilities  ability  able  abnormal  abnormally  \\\n",
       "0   0   0         0      0          0        0     0         0           0   \n",
       "1   0   0         0      0          0        0     0         0           0   \n",
       "2   0   0         0      0          0        0     0         0           0   \n",
       "3   0   0         0      0          0        0     0         0           0   \n",
       "4   0   0         0      0          0        0     0         0           0   \n",
       "\n",
       "   abound  ...  zircan  zk  zodiac  zodiacal  zodiacs  zodiacum  zone  zoom  \\\n",
       "0       0  ...       0   0       0         0        0         0     0     0   \n",
       "1       0  ...       0   0       1         0        0         0     0     0   \n",
       "2       0  ...       0   0       0         0        0         0     0     0   \n",
       "3       0  ...       0   0       0         0        0         0     0     0   \n",
       "4       0  ...       0   0       1         0        0         0     0     0   \n",
       "\n",
       "   zwillinge  zxmoaplo  \n",
       "0          0         0  \n",
       "1          0         0  \n",
       "2          0         0  \n",
       "3          0         0  \n",
       "4          0         0  \n",
       "\n",
       "[5 rows x 5721 columns]"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating df from the model\n",
    "df_words_cvec = pd.DataFrame(train_features_cvec.toarray(),\n",
    "                  columns=cvec.get_feature_names())\n",
    "df_words_cvec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>abducted</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abnormally</th>\n",
       "      <th>abound</th>\n",
       "      <th>...</th>\n",
       "      <th>zircan</th>\n",
       "      <th>zk</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zodiacal</th>\n",
       "      <th>zodiacs</th>\n",
       "      <th>zodiacum</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwillinge</th>\n",
       "      <th>zxmoaplo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5721 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa   ab  abducted  abhor  abilities  ability  able  abnormal  abnormally  \\\n",
       "0  0.0  0.0       0.0    0.0        0.0      0.0   0.0       0.0         0.0   \n",
       "1  0.0  0.0       0.0    0.0        0.0      0.0   0.0       0.0         0.0   \n",
       "2  0.0  0.0       0.0    0.0        0.0      0.0   0.0       0.0         0.0   \n",
       "3  0.0  0.0       0.0    0.0        0.0      0.0   0.0       0.0         0.0   \n",
       "4  0.0  0.0       0.0    0.0        0.0      0.0   0.0       0.0         0.0   \n",
       "\n",
       "   abound  ...  zircan   zk    zodiac  zodiacal  zodiacs  zodiacum  zone  \\\n",
       "0     0.0  ...     0.0  0.0  0.000000       0.0      0.0       0.0   0.0   \n",
       "1     0.0  ...     0.0  0.0  0.040109       0.0      0.0       0.0   0.0   \n",
       "2     0.0  ...     0.0  0.0  0.000000       0.0      0.0       0.0   0.0   \n",
       "3     0.0  ...     0.0  0.0  0.000000       0.0      0.0       0.0   0.0   \n",
       "4     0.0  ...     0.0  0.0  0.401363       0.0      0.0       0.0   0.0   \n",
       "\n",
       "   zoom  zwillinge  zxmoaplo  \n",
       "0   0.0        0.0       0.0  \n",
       "1   0.0        0.0       0.0  \n",
       "2   0.0        0.0       0.0  \n",
       "3   0.0        0.0       0.0  \n",
       "4   0.0        0.0       0.0  \n",
       "\n",
       "[5 rows x 5721 columns]"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating df from the model\n",
    "df_words_tvec = pd.DataFrame(train_features_tvec.toarray(),\n",
    "                  columns=tvec.get_feature_names())\n",
    "df_words_tvec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom display of df side-by-side. \n",
    "CSS code was taken from [here](https://stackoverflow.com/questions/38783027/jupyter-notebook-display-two-pandas-tables-side-by-side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output {\n",
       "    flex-direction: row;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSS = \"\"\"\n",
    ".output {\n",
    "    flex-direction: row;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "HTML('<style>{}</style>'.format(CSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>is_psy</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>moon</th>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>111</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chart</th>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>149</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venus</th>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sign</th>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sun</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saturn</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "is_psy    0   1\n",
       "moon    203   0\n",
       "house   188   0\n",
       "people  111  51\n",
       "chart   161   1\n",
       "like    149  11\n",
       "venus   132   0\n",
       "sign    129   0\n",
       "sun     125   0\n",
       "know    112   1\n",
       "saturn  105   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>is_psy</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>moon</th>\n",
       "      <td>17.997949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>16.950563</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chart</th>\n",
       "      <td>15.707989</td>\n",
       "      <td>0.208593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>7.443599</td>\n",
       "      <td>8.347398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sign</th>\n",
       "      <td>13.729905</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>10.921245</td>\n",
       "      <td>1.608285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venus</th>\n",
       "      <td>11.493820</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>10.495857</td>\n",
       "      <td>0.090052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>4.398885</td>\n",
       "      <td>5.842805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <td>0.810046</td>\n",
       "      <td>9.265572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "is_psy          0         1\n",
       "moon    17.997949  0.000000\n",
       "house   16.950563  0.000000\n",
       "chart   15.707989  0.208593\n",
       "people   7.443599  8.347398\n",
       "sign    13.729905  0.000000\n",
       "like    10.921245  1.608285\n",
       "venus   11.493820  0.000000\n",
       "know    10.495857  0.090052\n",
       "new      4.398885  5.842805\n",
       "study    0.810046  9.265572"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying top 10 most frequent words from \n",
    "# TfidfVectorizer and CountVectorizer for both subreddits\n",
    "\n",
    "top_10_words_cv = list(df_words_cvec.sum().sort_values(ascending=False).index)[:10]\n",
    "df_words_cvec['is_psy'] = y_train.values\n",
    "cv_train_small = df_words_cvec.groupby('is_psy')[top_10_words_cv].sum()\n",
    "\n",
    "top_10_words_tv = list(df_words_tvec.sum().sort_values(ascending=False).index)[:10]\n",
    "df_words_tvec['is_psy'] = y_train.values\n",
    "tv_train_small = df_words_tvec.groupby('is_psy')[top_10_words_tv].sum()\n",
    "\n",
    "display(cv_train_small.T)\n",
    "display(tv_train_small.T)\n",
    "\n",
    "# CountVectorizer           TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important words for classification are similar, but CountVectorizer gives more common words such as th, know, like because it only counts the word frequencies. TfidfVectorizer adjusts its scores for the fact that some words appear more frequently in general hance gives more relevant words. The decision is to use TfidfVectorizer for our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline model's accuracy is 0.55 (55%) of predicting true subreddit for a post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.552439\n",
       "1    0.447561\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is fitting 5 different models.\n",
    "\n",
    "3 Classifiers:\n",
    "    - Naive Bayes: MultinomialNB because all columns are integer counts.\n",
    "    - LogisticRegression \n",
    "    - KNeighborsClassifier \n",
    "And 2 Vectorizers:\n",
    "    - CountVectorizer (GridSearch through parameters)\n",
    "    - TfidfVectorizer (GridSearch through parameters)\n",
    "    \n",
    "Models will be evaluated based on 4 [metrics](#Evaluation): accuracy, precision, recall, f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_metrics(y_test, y_predicted):  \n",
    "    \"\"\"\n",
    "    Calculates accuracy, precision, recall, f1\n",
    "    \n",
    "    Takes:\n",
    "    y_test - pandas Series\n",
    "    y_predicted - pandas Series\n",
    "    \n",
    "    Prints accuracy, precision, recall, f1\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # set of predicted labels match the corresponding set of true labels\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    # ratio tp / (tp + fp)\n",
    "    precision = precision_score(y_test, y_predicted)             \n",
    "    # ratio tp / (tp + fn)\n",
    "    recall = recall_score(y_test, y_predicted)\n",
    "    # weighted average of the precision and recall\n",
    "    # F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    f1 = f1_score(y_test, y_predicted)\n",
    "    \n",
    "    print(f'accuracy {round(accuracy,3)}, precision {round(precision,3)},recall {round(recall,3)}, f1 {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_choosing(vectorizers,model,params,\n",
    "                   X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test):\n",
    "    '''\n",
    "    Evaluate model with two vectorizers\n",
    "    Takes:\n",
    "    vectorizers - list of vectorizers\n",
    "    model - initialized model name\n",
    "    params - parameters for GridSearchCV\n",
    "    X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test\n",
    "    \n",
    "    Prints  Cross_val_scores, \n",
    "            Best score of grid search,\n",
    "            Best parameters,\n",
    "            Test score\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    '''\n",
    "    for vectorizer in vectorizers:\n",
    "        print('============================')\n",
    "        print(str(vectorizer).split('(')[0])\n",
    "        print(str(model).split('(')[0])\n",
    "        pipe = Pipeline([\n",
    "                ('vect',vectorizer),\n",
    "                ('model',model)\n",
    "            ])\n",
    "        pipe_params = params\n",
    "        gs = GridSearchCV(pipe, \n",
    "                  param_grid=pipe_params,\n",
    "                  cv=3) \n",
    "        cross_scores = cross_val_score(gs,X_train,y_train)\n",
    "        gs.fit(X_train,y_train)\n",
    "        print(f'Cross_val_scores: {cross_scores}')\n",
    "        print(f'Best score of grid search: {gs.best_score_}')\n",
    "        print(f'Best parameters: {gs.best_params_}')\n",
    "        gs_model = gs.best_estimator_\n",
    "        gs_model.fit(X_train,y_train)\n",
    "        test_score = gs_model.score(X_test, y_test)\n",
    "        print(f'Test score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "# Modeling LogisticRegression with CountVectorizer and TfidfVectorizer\n",
    "# applying different hyperparameters\n",
    "\n",
    "%%time\n",
    "cvec = CountVectorizer(stop_words = all_stop_words)\n",
    "tvec = TfidfVectorizer(stop_words = all_stop_words)\n",
    "lr = LogisticRegression()\n",
    "params = {           \n",
    "            'vect__max_features':[2000,3000,5000],\n",
    "            'vect__min_df':[1,2,3],\n",
    "            'vect__max_df':[0.9,0.95],\n",
    "            'vect__ngram_range': [(1,1), (1,2)]\n",
    "            }\n",
    "best_param = model_choosing([cvec,tvec],lr,params)\n",
    "\n",
    "# Evaluating model with best hyperparameters\n",
    "# printing cross_val_scores, train score, test score, accuracy, precision, recall, f1 score\n",
    "\n",
    "print('====== Final model with best params for Vectorizer ======')\n",
    "tvec = TfidfVectorizer(best_param,stop_words = all_stop_words)\n",
    "X_train_tv = tvec.fit_transform(X_train)\n",
    "X_test_tv = tvec.transform(X_test)\n",
    "cross_scores = cross_val_score(lr,X_train_tv,y_train)\n",
    "print(f'Cross_val_scores: {[round(i,3) for i in cross_scores]}')\n",
    "lr.fit(X_train_tv,y_train)\n",
    "train_score = lr.score(X_train_tv, y_train)\n",
    "print(f'Train score: {round(train_score,3)}')\n",
    "test_score = lr.score(X_test_tv, y_test)\n",
    "print(f'Test score: {round(test_score,3)}')\n",
    "predictions = lr.predict(X_test_tv)\n",
    "model_metrics(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling KNeighborsClassifier with CountVectorizer and TfidfVectorizer\n",
    "# applying different hyperparameters\n",
    "\n",
    "%%time\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10)\n",
    "params = {           \n",
    "            'vect__max_features':[2000,3000,5000],\n",
    "            'vect__min_df':[1,2,3],\n",
    "            'vect__max_df':[0.9,0.95],\n",
    "            'vect__ngram_range': [(1,1), (1,2)],\n",
    "            }\n",
    "\n",
    "model_choosing([cvec,tvec],knn_model,params)\n",
    "\n",
    "# Evaluating model with best hyperparameters\n",
    "# printing cross_val_scores, train score, test score, accuracy, precision, recall, f1 score\n",
    "\n",
    "print('====== Final model with best params for Vectorizer ======')\n",
    "tvec_knn = TfidfVectorizer(best_param,stop_words = all_stop_words)\n",
    "X_train_tv_knn = tvec_knn.fit_transform(X_train)\n",
    "X_test_tv_knn = tvec_knn.transform(X_test)\n",
    "cross_scores = cross_val_score(knn_model,X_train_tv_knn,y_train)\n",
    "print(f'Cross_val_scores: {[round(i,3) for i in cross_scores]}')\n",
    "knn_model.fit(X_train_tv_knn,y_train)\n",
    "train_score = knn_model.score(X_train_tv_knn, y_train)\n",
    "print(f'Train score: {round(train_score,3)}')\n",
    "test_score = knn_model.score(X_test_tv_knn, y_test)\n",
    "print(f'Test score: {round(test_score,3)}')\n",
    "predictions = knn_model.predict(X_test_tv_knn)\n",
    "model_metrics(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling MultinomialNB with TfidfVectorizer\n",
    "# printing cross_val_scores, train score, test score, accuracy, precision, recall, f1 score\n",
    "\n",
    "%%time\n",
    "tvec = TfidfVectorizer(stop_words = all_stop_words)\n",
    "nb = MultinomialNB()\n",
    "X_train_tv = tvec.fit_transform(X_train)\n",
    "X_test_tv = tvec.transform(X_test)\n",
    "cross_scores = cross_val_score(nb,X_train_tv.todense(),y_train)\n",
    "print(f'Cross_val_scores: {[round(i,3) for i in cross_scores]}')\n",
    "nb.fit(X_train_tv.todense(),y_train)\n",
    "train_score = nb.score(X_train_tv.todense(), y_train)\n",
    "print(f'Train score: {round(train_score,3)}')\n",
    "test_score = nb.score(X_test_tv.todense(), y_test)\n",
    "print(f'Test score: {round(test_score,3)}')\n",
    "predictions = nb.predict(X_test_tv)\n",
    "model_metrics(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Vectorizer      | Model                | Cross_val_scores_train (accuracy) | Train accuracy | Test accuracy | Test precision | Test recall | Test f1 |\n",
    "| --------------- | -------------------- | --------------------------------- | -------------- | ------------- | -------------- | ----------- | ------- |\n",
    "| TfidfVectorizer | MultinomialNB        | 0.902, 0.927, 0.915, 0.909, 0.884 | 0.993          | 0.921         | 0.984          | 0.837       | 0.904   |\n",
    "| TfidfVectorizer | LogisticRegression   | 0.97, 0.933, 0.945, 0.957, 0.896  | 0.998          | 0.945         | 0.924          | 0.956       | 0.94    |\n",
    "| TfidfVectorizer | KNeighborsClassifier | 0.866, 0.89, 0.909, 0.884, 0.878  | 0.913          | 0.904         | 0.965          | 0.815       | 0.883   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is shown on the table above - LogisticRegression is the best model with TfidfVectorizer. We can see that cross-validation scores vary as well as train and test score. It means that our model is overfitted, but the test score is still very high and higher than other models. Also, LogisticRegression showed the best recall that means that classifier found almost all positive samples (psychological subreddit posts).\n",
    "\n",
    "All the models perform better with TfidfVectorizer. MultinomialNB and KNeighborsClassifier also showed pretty decent scores. KNeighborsClassifier turned out to be less overfitted in comparison with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with list of true values and predicted probabilities based on our model\n",
    "pred_proba = [i[1] for i in lr.predict_proba(X_test_tv)]\n",
    "pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating distribution of divided probability for two subreddits\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "# Create two histograms of observations.\n",
    "plt.hist(pred_df[pred_df['true_values'] == 0]['pred_probs'],\n",
    "         bins=25,\n",
    "         color='#65a8a7',\n",
    "         alpha = 0.5,\n",
    "         label='Astrology')\n",
    "plt.hist(pred_df[pred_df['true_values'] == 1]['pred_probs'],\n",
    "         bins=25,\n",
    "         color='#fcba03',\n",
    "         alpha = 0.5,\n",
    "         label='Psychology')\n",
    "\n",
    "# Add vertical line at P(Outcome = 1) = 0.5.\n",
    "plt.vlines(x=0.5,\n",
    "           ymin = 0,\n",
    "           ymax = 65,\n",
    "           color='r',\n",
    "           linestyle = '--')\n",
    "\n",
    "# Label axes.\n",
    "plt.title('Distribution of Probability', fontsize=22)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xlabel('Predicted Probability that Outcome = 1', fontsize=18)\n",
    "plt.text(y = 40,x = 0.1,s = 'True negative',color='blue')\n",
    "plt.text(y = 10,x = 0.25,s = 'False negative',color='orange')\n",
    "plt.text(y = 10,x = 0.55,s = 'False positive',color='blue')\n",
    "plt.text(y = 40,x = 0.75,s = 'True positive',color='orange')\n",
    "# Create legend.\n",
    "plt.legend(fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that probabilities of Astrological and Psychological subreddits are differently distributed. The overlapped area is pretty small. It means that our best model classifying well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create threshold values. (Dashed red line in image.)\n",
    "thresholds = np.linspace(0, 1, 200)\n",
    "\n",
    "# Define function to calculate sensitivity. (True positive rate.)\n",
    "def TPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_positive = df[(df[true_col] == 1) & (df[pred_prob_col] >= threshold)].shape[0]\n",
    "    false_negative = df[(df[true_col] == 1) & (df[pred_prob_col] < threshold)].shape[0]\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "    \n",
    "\n",
    "# Define function to calculate 1 - specificity. (False positive rate.)\n",
    "def FPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_negative = df[(df[true_col] == 0) & (df[pred_prob_col] <= threshold)].shape[0]\n",
    "    false_positive = df[(df[true_col] == 0) & (df[pred_prob_col] > threshold)].shape[0]\n",
    "    return 1 - (true_negative / (true_negative + false_positive))\n",
    "    \n",
    "# Calculate sensitivity & 1-specificity for each threshold between 0 and 1.\n",
    "tpr_values = [TPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "fpr_values = [FPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "\n",
    "# Plot ROC curve.\n",
    "plt.plot(fpr_values, # False Positive Rate on X-axis\n",
    "         tpr_values, # True Positive Rate on Y-axis\n",
    "         label='ROC Curve')\n",
    "\n",
    "# Plot baseline. (Perfect overlap between the two populations.)\n",
    "plt.plot(np.linspace(0, 1, 200),\n",
    "         np.linspace(0, 1, 200),\n",
    "         label='baseline',\n",
    "         linestyle='--')\n",
    "\n",
    "# Label axes.\n",
    "plt.title(f'ROC Curve with AUC = {round(roc_auc_score(pred_df[\"true_values\"], pred_df[\"pred_probs\"]),3)}', fontsize=22)\n",
    "plt.ylabel('Recall', fontsize=18)\n",
    "plt.xlabel('1 - Specificity', fontsize=18)\n",
    "\n",
    "# Create legend.\n",
    "plt.legend(fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC is a probability curve and AUC represents degree or measure of separability. It tells that our model is capable of distinguishing between two classes. AUC = 0.991, that means that positive and negative classes are separated good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the coefficient of the words the prediction was made on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating df with words, number of words, coefficients and exponent of coefficients\n",
    "# We have to exponent out coefficient because LogisticRegression usr logit for calculation\n",
    "predictors = pd.DataFrame({\n",
    "    'word':list(tvec.get_feature_names()),\n",
    "    'word_count':list(tvec.vocabulary_.values()),\n",
    "    'coef':lr.coef_[0],\n",
    "    'exp_coef':np.exp(lr.coef_)[0]\n",
    "})\n",
    "predictors.sort_values(by='coef',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above demonstrates words which have the highest coefficient in the prediction of psychological class. Some words are clearly from psychological vocabulary: psychreg (website name), brain, mental, anxiety, cognitive, behavior. But some words are from general vocabulary: finds, people, women, covid. The model can be better generalize for distinguishing psychological posts from other posts if these words will be revisited and may be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.sort_values(by='coef',ascending=True).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above demonstrates words which have a negative coefficient in the prediction of psychological class. These words refer to astrological category. The words are clearly from astrological vocabulary: chart, moon, house, sign, saturn. But some words are general: know, like, think. For better performance of model, it would be better to add them to stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassification analisys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at mislassified posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = lr.predict(X_test_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Astrology [True Negatives]: %s\" % tn)\n",
    "print(\"False Psychology [False Positives]: %s\" % fp)\n",
    "print(\"False Astrology [False Negatives]: %s\" % fn)\n",
    "print(\"True Psychology [True Positives]: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lr,X_test_tv,y_test,normalize='true');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, it can be noticed that percent of misclassification is 6.4% for false positive (Astrological posts were classified as psychological) and 4.4% for false negative (Psychological posts were classified as astrological). True negative (astrological class) were identified a bit better than true positive (psychological class). But slightly unbalanced classes of data should be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at mislaccified posts\n",
    "probabilities = pd.DataFrame(lr.predict_proba(X_test_tv),columns=['astr_proba','psy_proba'])\n",
    "probabilities['subred'] = y_test.values\n",
    "probabilities['predict'] = predictions\n",
    "probabilities['text'] = X_test.values\n",
    "probabilities['num_comments'] = list(df.loc[y_test.index,'num_comments'])\n",
    "probabilities['ups'] = list(df.loc[y_test.index,'ups'])\n",
    "probabilities['len_text'] = list(df.loc[y_test.index,'len_text'])\n",
    "misclassified = probabilities[probabilities['subred']!=probabilities['predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(misclassified[misclassified['subred'] ==1].head(34))\n",
    "display(misclassified[misclassified['subred'] ==1].head(34))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some posts which were classified as astrological have general information in them but others are clearly contained psychological vocabulary. These posts are quite different in terms of length of text (but mostly small number)and meaning of posts. Most probabilities fro psychology is higher than 0.5 so the possible solution will be to drop a threshold for classification.\n",
    "\n",
    "Let's see false positive than."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(misclassified[misclassified['subred'] ==0].head(34))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All texts contain astrological vocabulary, the misclassification can be due to misspelling some words. Words such as astrology, astrological were removed what leads to the change of meaning of the texts. Also, some probabilities are high enough to separate the classes so changing a threshold can be a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud of misclassified posts\n",
    "\n",
    "comment_words = ''\n",
    "comment_words += \" \".join(word for word in misclassified['text'])+\" \"\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = all_stop_words, \n",
    "                min_font_size = 10).generate(comment_words) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.title('Words from misclassified posts')\n",
    "plt.tight_layout(pad = 0)\n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is noticeable that most of the words are from general vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further research suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the model limitation some suggestions for further research can be made:\n",
    "\n",
    "- Scrape more data for each subreddit.\n",
    "- Use fully balanced classes for better predictions.\n",
    "- Use the same balance of classes as a number of all posts in subreddits for better generalization of a model.\n",
    "- Use additional features such as number of comments, number of ups and length of text for extension of the model.\n",
    "- Make a decision about general words: some general words can lead to misclassification. \n",
    "- Make a decision about keeping specific words. Words such as psychology and astrology were removed from task complications and educational purpose only in this project.\n",
    "- Filter posts with a small number of words in selftext and title.\n",
    "- Use more advanced models.\n",
    "\n",
    "Ideas for additional research:\n",
    "\n",
    "- Exploring posts with a high number of commentaries and ups.\n",
    "- Expend a model for more broad classification:\n",
    "    - Distinguishing psychological posts from other posts with different topics.\n",
    "    - Explore how psychology differs from science subreddit.\n",
    "    - Add more than two classes.\n",
    "- Build a model for posts with a small length of texts.\n",
    "- Extend dataset with posts which were published during longer period of time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
